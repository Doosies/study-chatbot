import streamlit as st
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from langchain_openai import ChatOpenAI
from langchain_classic import hub
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_classic.chains import RetrievalQA

load_dotenv()

def get_ai_message(user_message: str) -> str:
  embedding = OpenAIEmbeddings(model="text-embedding-3-large")
  index_name = "inflearn1"
  data_base = PineconeVectorStore.from_existing_index(index_name,embedding)
  retriever = data_base.as_retriever(search_kwargs={'k': 10})

  llm = ChatOpenAI(model='gpt-4o')
  prompt = hub.pull("rlm/rag-prompt")

  dictionary = ["ì‚¬ëŒì„ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ -> ê±°ì£¼ì"]
  converted_prompt = ChatPromptTemplate.from_template(f"""
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³ , ìš°ë¦¬ì˜ ì‚¬ì „ì„ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•´ì£¼ì„¸ìš”.
    ë§Œì•½ ë³€ê²½í•  í•„ìš”ê°€ ì—†ë‹¤ê³  íŒë‹¨ë˜ë©´, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•˜ì§€ ì•ˆì•„ë„ ë©ë‹ˆë‹¤.
    ì‚¬ì „: {dictionary}
    
    ì§ˆë¬¸: {{question}}
  """)

  dictionary_chain = converted_prompt | llm | StrOutputParser()
  qa_chain = RetrievalQA.from_chain_type(
    llm,
    retriever=retriever,
    chain_type_kwargs={"prompt": prompt}
  )
  tax_chain = {"query": dictionary_chain} | qa_chain

  ai_response = tax_chain.invoke({"question": user_message})
  
  return ai_response['result']

st.set_page_config(page_title="ì†Œë“ì„¸ ì±—ë´‡", page_icon="ğŸ¤–")
st.title("ì±—ë´‡!!")
st.caption("ì†Œë“ì„¸ì— ê´€ë ¨ëœ ëª¨ë“ ê²ƒì„ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.")

if 'message_list' not in st.session_state:
  st.session_state.message_list = []
  
for message in st.session_state.message_list:
    with st.chat_message(message["role"]):
      st.write(message["content"])
      
if user_question := st.chat_input(placeholder="ì…ë ¥í•´ì£¼ì„¸ìš”"):
  with st.chat_message("user"):
    st.write(user_question)
  st.session_state.message_list.append({"role": "user", "content": user_question})
  
  with st.spinner("ë‹µë³€ ìƒì„±ì¤‘..."):
    ai_message = get_ai_message(user_question)
    
    with st.chat_message("ai"):
      st.write(ai_message)
    st.session_state.message_list.append({"role": "ai", "content": ai_message})
